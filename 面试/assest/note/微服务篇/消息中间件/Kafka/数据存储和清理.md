> **面试官**：Kafka数据清理机制了解过嘛
>
> **候选人**：
>
> 嗯，了解过~~
>
> Kafka中topic的数据存储在分区上，分区如果文件过大会分段存储segment
>
> 每个分段都在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储，这样分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理。
>
> 在kafka中提供了两个日志的清理策略：
>
> 第一，根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时（ 7天）
>
> 第二是根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。这个默认是关闭的
>
> 这两个策略都可以通过kafka的broker中的配置文件进行设置